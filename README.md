# Звіт: Лабораторної роботи 1: Класифікація

## 1. Мета та завдання

Метою цього практичного проєкту було:

- Реалізувати на Python чотири алгоритми класифікації:
  1. One‑Rule
  2. Gaussian Naive Bayes
  3. Decision Tree
  4. kNN
- Підібрати придатний датасет з Kaggle, обрано Rain in Australia.
- Провести цикл попередньої обробки даних:
  - Видалення некорисних ознак (Date, RISK_MM, Evaporation, Sunshine)
  - Імпутація пропусків
  - Кодування категоріальних змінних (one-hot, бінарне кодування)
  - Стандартизація числових ознак
  - Додавання часових ознак та їх циклічне кодування.
- Навчити моделі, виконати тюнінг гіперпараметрів (max_depth для Decision Tree, k для kNN).
- Оцінити кожну модель за метриками Accuracy, Precision, Recall, F1 та порівнят результати.

## 2. Дані

- **Джерело**: Kaggle Rain in Australia weatherAUS.csv.
- **Розмірність**: 142 193 записів, 23 вихідні ознаки + цільова `RainTomorrow`.
- **Ціль**: бінарна змінна — чи йде дощ наступного дня (Yes/No).

## 3. Попередня обробка даних

1. **Видалення стовпців**
   - `Date` рядок дата, `RISK_MM` витік інформації, `Evaporation`, `Sunshine` більше 40% пропусків.
2. **Імпутація пропусків**
   - Числові ознаки → медіана.
   - Категоріальні (напрямок вітру, хмарність) → мода.
3. **Кодування**
   - `RainToday`, `RainTomorrow` → 1/0.
   - Onehot для `Location`, `WindGustDir`, `WindDir9am`, `WindDir3pm`.
4. **Нормалізація**
   - `StandardScaler` до всіх числових ознак.
5. **Часові ознаки**
```python
df['Date'] = pd.to_datetime(df['Date'])
df['month'] = df['Date'].dt.month
df['day_of_week'] = df['Date'].dt.dayofweek
# циклічне кодування:
df['month_sin'] = np.sin(2*np.pi*df['month']/12)
df['month_cos'] = np.cos(2*np.pi*df['month']/12)
df['dow_sin'] = np.sin(2*np.pi*df['day_of_week']/7)
df['dow_cos'] = np.cos(2*np.pi*df['day_of_week']/7)
df.drop(columns=['Date'], inplace=True)
```

## 4. Реалізація моделей та тюнінг

### One‑Rule
- Дискретзація ознак на 5 квантильних бінів.
- Підбір ознаки з мінімальною кількістю помилок.

### Gaussian Naive Bayes
- `sklearn.naive_bayes.GaussianNB` без додаткових налаштувань.

### Decision Tree
- `DecisionTreeClassifier` з глибиною:
  ```
  depth=3  → acc=0.830
  depth=5  → acc=0.837
  depth=10 → acc=0.841  ← обрано
  depth=None → acc=0.791
  ```

### kNN
- `KNeighborsClassifier` (евклідова відстань):
  ```
  k=1   → acc=0.802
  k=5   → acc=0.836
  k=9   → acc=0.840
  k=15  → acc=0.842  ← обрано
  ```

## 5. Результати

| Модель             | Accuracy | Precision_1 | Recall_1 | F1_1 |
|--------------------|:--------:|:-----------:|:--------:|:-----:|
| One‑Rule           | 0.810    | 0.591       | 0.496    | 0.539 |
| Naive Bayes        | 0.647    | 0.356       | 0.710    | 0.474 |
| Decision Tree (10) | 0.841    | 0.713       | 0.489    | 0.581 |
| kNN (k=15)         | 0.842    | 0.739       | 0.456    | 0.564 |

> _Метрики для позитивного класу "дощ."_

## 6. Висновки
 B результаті практичного дослідження було досліджено роботу чотирьoх алгоритмів класифікації на даних з Kaggle: One‑Rule, Naive Bayes, Decision Tree та kNN. Було виконано повну попередню обробку даних, видалено витоки, імпутовано пропуски, закодовано категоріальні та циклічні часові ознаки. Налаштування гіперпараметрів показало, що Decision Tree (глибина=10) та k‑NN (k=15) досягають найвищої точності близько 84%, проте мають низький recall для прогнозу дощу. Отримані результати свідчать про необхідність оптимізації під підвищення чутливості дощових днів або застосування ансамблевих моделей.